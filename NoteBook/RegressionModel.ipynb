{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         high       low      open  volumefrom      volumeto  \\\n",
      "time                                                                          \n",
      "2021-02-25 11:00:00  50442.19  49621.98  49622.62     2093.44  1.046078e+08   \n",
      "2021-02-25 12:00:00  50763.45  50139.44  50336.98     2216.61  1.118364e+08   \n",
      "\n",
      "                        close conversionType conversionSymbol  \n",
      "time                                                           \n",
      "2021-02-25 11:00:00  50336.98         direct                   \n",
      "2021-02-25 12:00:00  50675.17         direct                   \n"
     ]
    }
   ],
   "source": [
    "# machine learning classification\n",
    "from pyforest import *\n",
    "import datetime, pickle, copy, warnings\n",
    "import cryptocompare\n",
    "import requests\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from time import time\n",
    "from pandas import DataFrame, concat\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "from pandas import DataFrame, concat\n",
    "\n",
    "\n",
    "apiKey = \"43b01c420b66888ce4c91b364647600814578c186e8604322152f44c641ebbc1\"\n",
    "url = \"https://min-api.cryptocompare.com/data/histohour\"\n",
    "\n",
    "# BTC 1st 2000 datapoints\n",
    "payload = {\"api_key\": apiKey, \"fsym\": \"BTC\", \"tsym\": \"USD\", \"limit\": 2000}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin1 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin1[\"time\"] = pd.to_datetime(BitCoin1[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin1.set_index(\"time\", inplace=True)\n",
    "\n",
    "# 2nd 2000 datapoints\n",
    "payload = {\n",
    "    \"api_key\": apiKey,\n",
    "    \"fsym\": \"BTC\",\n",
    "    \"tsym\": \"USD\",\n",
    "    \"limit\": 2000,\n",
    "    \"toTs\": (1601632800),\n",
    "}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin2 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin2[\"time\"] = pd.to_datetime(BitCoin2[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin2.set_index(\"time\", inplace=True)\n",
    "\n",
    "# 3rd 2000 datapoints\n",
    "payload = {\n",
    "    \"api_key\": apiKey,\n",
    "    \"fsym\": \"BTC\",\n",
    "    \"tsym\": \"USD\",\n",
    "    \"limit\": 2000,\n",
    "    \"toTs\": (1593572400),\n",
    "}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin3 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin3[\"time\"] = pd.to_datetime(BitCoin3[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin3.set_index(\"time\", inplace=True)\n",
    "\n",
    "# 4th 2000 datapoints\n",
    "payload = {\n",
    "    \"api_key\": apiKey,\n",
    "    \"fsym\": \"BTC\",\n",
    "    \"tsym\": \"USD\",\n",
    "    \"limit\": 2000,\n",
    "    \"toTs\": (1596571200),\n",
    "}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin4 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin4[\"time\"] = pd.to_datetime(BitCoin4[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin4.set_index(\"time\", inplace=True)\n",
    "\n",
    "# combining all bitcoin data (8000 data points)\n",
    "combineData1 = BitCoin2.append(BitCoin1)\n",
    "\n",
    "combineData2 = BitCoin3.append(combineData1)\n",
    "\n",
    "BitCoin = BitCoin4.append(combineData2)  # final BitCoin dataset\n",
    "\n",
    "print(BitCoin.tail(2))\n",
    "# saving btc data set\n",
    "BitCoin.to_csv(\"BitCoinRaw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         high       low      open     close      Lag1  \\\n",
      "time                                                                    \n",
      "2021-02-25 08:00:00  50559.02  49630.28  50471.50  49738.19  50471.50   \n",
      "2021-02-25 09:00:00  49890.11  48688.16  49738.19  49023.64  49738.19   \n",
      "2021-02-25 10:00:00  49798.13  48889.18  49023.64  49622.62  49023.64   \n",
      "2021-02-25 11:00:00  50442.19  49621.98  49622.62  50336.98  49622.62   \n",
      "2021-02-25 12:00:00  50763.45  50139.44  50336.98  50675.17  50336.98   \n",
      "\n",
      "                         Lag2      Lag3      Lag4      Lag5      Lag6  ...  \\\n",
      "time                                                                   ...   \n",
      "2021-02-25 08:00:00  50503.52  50432.31  49652.82  50277.51  50684.94  ...   \n",
      "2021-02-25 09:00:00  50471.50  50503.52  50432.31  49652.82  50277.51  ...   \n",
      "2021-02-25 10:00:00  49738.19  50471.50  50503.52  50432.31  49652.82  ...   \n",
      "2021-02-25 11:00:00  49023.64  49738.19  50471.50  50503.52  50432.31  ...   \n",
      "2021-02-25 12:00:00  49622.62  49023.64  49738.19  50471.50  50503.52  ...   \n",
      "\n",
      "                         Lag8       S_10      Corr      d_20          5EMA  \\\n",
      "time                                                                         \n",
      "2021-02-25 08:00:00  50535.37  50253.987 -0.023930  37749.92  50142.728228   \n",
      "2021-02-25 09:00:00  50505.54  50182.534 -0.509298  37287.40  49769.698818   \n",
      "2021-02-25 10:00:00  50684.94  50091.259 -0.503736  37446.83  49720.672546   \n",
      "2021-02-25 11:00:00  50277.51  50074.403 -0.402178  37722.95  49926.108364   \n",
      "2021-02-25 12:00:00  49652.82  50073.426 -0.197620  37910.18  50175.795576   \n",
      "\n",
      "                            10EMA         20EMA       mean   returns  \\\n",
      "time                                                                   \n",
      "2021-02-25 08:00:00  50099.800691  49971.373944  50094.650 -1.452919   \n",
      "2021-02-25 09:00:00  49904.135111  49881.113568  49289.135 -1.436622   \n",
      "2021-02-25 10:00:00  49852.950545  49856.495133  49343.655  1.221819   \n",
      "2021-02-25 11:00:00  49940.955901  49902.255597  50032.085  1.439585   \n",
      "2021-02-25 12:00:00  50074.449373  49975.866492  50451.445  0.671852   \n",
      "\n",
      "                           volume  \n",
      "time                               \n",
      "2021-02-25 08:00:00  9.269003e+07  \n",
      "2021-02-25 09:00:00  1.834303e+08  \n",
      "2021-02-25 10:00:00  1.031484e+08  \n",
      "2021-02-25 11:00:00  1.046057e+08  \n",
      "2021-02-25 12:00:00  1.118342e+08  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"BitCoinRaw.csv\")\n",
    "df.set_index(\"time\", inplace=True)\n",
    "\n",
    "df.drop(columns=[\"conversionType\", \"conversionSymbol\"], axis=1, inplace=True)\n",
    "\n",
    "values = DataFrame(df.close.values)\n",
    "lags = 8\n",
    "columns = [values]\n",
    "for i in range(1, (lags + 1)):\n",
    "    columns.append(values.shift(i))\n",
    "\n",
    "dt = concat(columns, axis=1)\n",
    "\n",
    "columns = [\"Lag\"]\n",
    "for i in range(1, (lags + 1)):\n",
    "    columns.append(\"Lag\" + str(i))\n",
    "dt.columns = columns\n",
    "dt.index = df.index\n",
    "\n",
    "finalDataSet = concat([df, dt], axis=1)\n",
    "\n",
    "finalDataSet.dropna(inplace=True)\n",
    "\n",
    "finalDataSet[\"S_10\"] = finalDataSet[\"close\"].rolling(window=10).mean()\n",
    "\n",
    "finalDataSet[\"Corr\"] = (\n",
    "    finalDataSet[\"close\"].rolling(window=10).corr(finalDataSet[\"S_10\"])\n",
    ")\n",
    "\n",
    "finalDataSet[\"d_20\"] = finalDataSet[\"close\"].shift(480)\n",
    "\n",
    "finalDataSet[\"5EMA\"] = (\n",
    "    finalDataSet[\"close\"].ewm(span=5, adjust=True, ignore_na=True).mean()\n",
    ")\n",
    "\n",
    "finalDataSet[\"10EMA\"] = (\n",
    "    finalDataSet[\"close\"].ewm(span=10, adjust=True, ignore_na=True).mean()\n",
    ")\n",
    "\n",
    "finalDataSet[\"20EMA\"] = (\n",
    "    finalDataSet[\"close\"].ewm(span=20, adjust=True, ignore_na=True).mean()\n",
    ")\n",
    "\n",
    "finalDataSet[\"mean\"] = (finalDataSet[\"low\"] + finalDataSet[\"high\"]) / 2\n",
    "\n",
    "finalDataSet[\"returns\"] = (\n",
    "    (finalDataSet[\"close\"] - finalDataSet[\"open\"]) / finalDataSet[\"open\"] * 100.0\n",
    ")\n",
    "\n",
    "finalDataSet[\"volume\"] = finalDataSet[\"volumeto\"] - finalDataSet[\"volumefrom\"]\n",
    "\n",
    "finalDataSet.drop([\"volumefrom\", \"volumeto\"], 1, inplace=True)\n",
    "\n",
    "finalDataSet.dropna(inplace=True)\n",
    "\n",
    "finalDataSet = finalDataSet.drop([\"Lag\"], axis=1)\n",
    "\n",
    "finalDataSet = finalDataSet.astype(float)\n",
    "\n",
    "finalDataSet = finalDataSet.sort_index(ascending=True)\n",
    "# dataframe.head(2)\n",
    "\n",
    "# save data\n",
    "finalDataSet.to_csv(\"finalDataSet.csv\", header=True)\n",
    "\n",
    "print(finalDataSet.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import concat, DataFrame\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import sklearn.externals\n",
    "import joblib\n",
    "\n",
    "finalDataSet = pd.read_csv(\"finalDataSet.csv\")\n",
    "finalDataSet.set_index(\"time\", inplace=True)\n",
    "# print(df.tail())\n",
    "\n",
    "\n",
    "foreCastColumn = \"close\"  # creating label\n",
    "\n",
    "foreCastOut = int(12)  # prediction for next 12 hrs\n",
    "\n",
    "finalDataSet[\"label\"] = finalDataSet[foreCastColumn].shift(-foreCastOut)\n",
    "\n",
    "X = np.array(finalDataSet.drop([\"label\"], axis=1))\n",
    "\n",
    "# normalize data\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "X_foreCastOut = X[-foreCastOut:]\n",
    "\n",
    "X = X[:-foreCastOut]\n",
    "\n",
    "finalDataSet.dropna(inplace=True)\n",
    "\n",
    "y = np.array(finalDataSet[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test data set\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 687328761.7767327, tolerance: 14064793.060788458\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25028075.47073871, tolerance: 123419.72625487612\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35966775.19883192, tolerance: 208018.32587141843\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38246193.177137166, tolerance: 220096.64458226462\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51397960.418132044, tolerance: 438252.9609825682\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.85 (+/- 0.28)\n",
      "Intercept: 16314.030249500713\n",
      "Slope: 8182.873467877099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68759993.41860785, tolerance: 783644.8973368459\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# regression model\n",
    "Model = ElasticNet(alpha=0.0001, l1_ratio=0.5, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# cross validated accucary on train set\n",
    "scores = cross_val_score(Model, X_train, y_train, cv=tscv)\n",
    "\n",
    "print(\"Training Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Intercept:\", Model.intercept_)\n",
    "print(\"Slope:\", Model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Training metrics  Validation metrics\n",
      "R-squared                           0.990               0.944\n",
      "Mean Absolute Error               161.773            1337.346\n",
      "Root Mean Squared Error           464.546            1763.592\n",
      "Relative Absolute Error             0.056               0.208\n",
      "Relative Squared Error              0.010               0.056\n"
     ]
    }
   ],
   "source": [
    "# prediction on training\n",
    "trainPredict = Model.predict(X_train)\n",
    "r_squared = r2_score(y_train, trainPredict)\n",
    "mae = np.mean(abs(trainPredict - y_train))\n",
    "rmse = np.sqrt(np.mean((trainPredict - y_train) ** 2))\n",
    "rae = np.mean(abs(trainPredict - y_train)) / np.mean(abs(y_train - np.mean(y_train)))\n",
    "rse = np.mean((trainPredict - y_train) ** 2) / np.mean(\n",
    "    (y_train - np.mean(y_train)) ** 2\n",
    ")\n",
    "sumOfDf = DataFrame(\n",
    "    index=[\n",
    "        \"R-squared\",\n",
    "        \"Mean Absolute Error\",\n",
    "        \"Root Mean Squared Error\",\n",
    "        \"Relative Absolute Error\",\n",
    "        \"Relative Squared Error\",\n",
    "    ]\n",
    ")\n",
    "sumOfDf[\"Training metrics\"] = [r_squared, mae, rmse, rae, rse]\n",
    "\n",
    "# prediction of test\n",
    "testPredict = Model.predict(X_test)\n",
    "r_squared = r2_score(y_test, testPredict)\n",
    "mae = np.mean(abs(testPredict - y_test))\n",
    "rmse = np.sqrt(np.mean((testPredict - y_test) ** 2))\n",
    "rae = np.mean(abs(testPredict - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\n",
    "rse = np.mean((testPredict - y_test) ** 2) / np.mean((y_test - np.mean(y_test)) ** 2)\n",
    "\n",
    "sumOfDf[\"Validation metrics\"] = [r_squared, mae, rmse, rae, rse]\n",
    "sumOfDf = sumOfDf.round(decimals=3)\n",
    "\n",
    "print(sumOfDf)  # accuracy check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file in the current working directory\n",
    "fileName = \"ElasticModel.pkl\"\n",
    "joblib.dump(Model, fileName)\n",
    "\n",
    "# Load from file\n",
    "ElasticModel = joblib.load(fileName)\n",
    "# ElasticModel.predict(X_test)\n",
    "# print(r2_score(y_test, ElasticModel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, convert and predict with ONNX Runtime\n",
    "\n",
    "### Backend\n",
    "\n",
    "sklearn-onnx converts models in ONNX format which can be then used to compute predictions with the backend of your choice. However, there exists a way to automatically check every converter with onnxruntime, onnxruntime-gpu. Every converter is tested with this backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skl2onnx\n",
      "  Downloading skl2onnx-1.7.0-py2.py3-none-any.whl (191 kB)\n",
      "Collecting onnx>=1.2.1\n",
      "  Downloading onnx-1.8.1-cp38-cp38-win_amd64.whl (6.9 MB)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from skl2onnx) (1.5.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.15.2-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: six in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from skl2onnx) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from skl2onnx) (1.19.2)\n",
      "Collecting onnxconverter-common>=1.5.1\n",
      "  Downloading onnxconverter_common-1.7.0-py2.py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from skl2onnx) (0.23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (3.7.4.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19->skl2onnx) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19->skl2onnx) (0.17.0)\n",
      "Installing collected packages: protobuf, onnx, onnxconverter-common, skl2onnx\n",
      "Successfully installed onnx-1.8.1 onnxconverter-common-1.7.0 protobuf-3.15.2 skl2onnx-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into ONNX format\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType, Int64TensorType, DictionaryType, SequenceType\n",
    "\n",
    "# input tensors of model: list of ('<wanted name of tensor>', DataType('<shape>'))\n",
    "initialType = [('float_input', FloatTensorType([None, 21]))]\n",
    "\n",
    "onx = convert_sklearn(Model, initial_types=initialType)\n",
    "\n",
    "with open(\"ElasticModel.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.6.0-cp38-cp38-win_amd64.whl (4.2 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from onnxruntime) (1.19.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from onnxruntime) (3.15.2)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\sarit\\anaconda3\\lib\\site-packages (from protobuf->onnxruntime) (1.15.0)\n",
      "Installing collected packages: onnxruntime\n",
      "Successfully installed onnxruntime-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443247411748621"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "\n",
    "session = rt.InferenceSession(\"ElasticModel.onnx\")\n",
    "\n",
    "inputName = session.get_inputs()[0].name\n",
    "\n",
    "labelName = session.get_outputs()[0].name\n",
    "\n",
    "predictionOnx = session.run([labelName], {inputName: X_test.astype(np.float32)})[0]\n",
    "\n",
    "r2_score(y_test, predictionOnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 hours forecast (hourly):\n",
      "                  time      Forecast\n",
      "0  2021-02-24 21:00:00  49809.559723\n",
      "1  2021-02-24 22:00:00  49683.454960\n",
      "2  2021-02-24 23:00:00  50486.824487\n",
      "3  2021-02-25 00:00:00  51455.979472\n",
      "4  2021-02-25 01:00:00  51587.313733\n",
      "5  2021-02-25 02:00:00  51616.122748\n",
      "6  2021-02-25 03:00:00  51378.035669\n",
      "7  2021-02-25 04:00:00  51043.579239\n",
      "8  2021-02-25 05:00:00  51207.272646\n",
      "9  2021-02-25 06:00:00  51419.231345\n",
      "10 2021-02-25 07:00:00  51383.407690\n",
      "11 2021-02-25 08:00:00  51347.314168\n"
     ]
    }
   ],
   "source": [
    "# forecast future 12 hrs values\n",
    "foreCastFutureValues = DataFrame(ElasticModel.predict(X_foreCastOut))\n",
    "# print(foreCastFutureValues)\n",
    "\n",
    "# assigning names to columns\n",
    "foreCastFutureValues.rename(columns={0: \"Forecast\"}, inplace=True)\n",
    "\n",
    "newDataframe = finalDataSet.tail(foreCastOut)\n",
    "\n",
    "newDataframe.reset_index(inplace=True)\n",
    "\n",
    "# Fixing future datetime\n",
    "newDataframe = newDataframe.append(\n",
    "    DataFrame(\n",
    "        {\n",
    "            \"time\": pd.date_range(\n",
    "                start=newDataframe.time.iloc[-1],\n",
    "                periods=(len(newDataframe) + 1),\n",
    "                freq=\"H\",\n",
    "                closed=\"right\",\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "newDataframe.set_index(\"time\", inplace=True)\n",
    "\n",
    "newDataframe = newDataframe.tail(foreCastOut)\n",
    "\n",
    "foreCastFutureValues.index = newDataframe.index\n",
    "\n",
    "print(\"12 hours forecast (hourly):\")\n",
    "foreCastFutureValues.reset_index(inplace=True)\n",
    "\n",
    "print(foreCastFutureValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaa484b042fbed4d21ad19847f11dc808b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
