{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         high       low      open  volumefrom     volumeto  \\\n",
      "time                                                                         \n",
      "2021-02-25 07:00:00  50603.54  50158.30  50503.52     1601.87  80846961.24   \n",
      "2021-02-25 08:00:00  50559.02  50222.74  50471.50      394.02  19858317.73   \n",
      "\n",
      "                        close conversionType conversionSymbol  \n",
      "time                                                           \n",
      "2021-02-25 07:00:00  50471.50         direct                   \n",
      "2021-02-25 08:00:00  50402.66         direct                   \n"
     ]
    }
   ],
   "source": [
    "# machine learning classification\n",
    "from pyforest import *\n",
    "import datetime, pickle, copy, warnings\n",
    "import cryptocompare\n",
    "import requests\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from time import time\n",
    "from pandas import DataFrame, concat\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "from pandas import DataFrame, concat\n",
    "\n",
    "\n",
    "apiKey = \"xxxxxxxxxxx\"\n",
    "url = \"https://min-api.cryptocompare.com/data/histohour\"\n",
    "\n",
    "# BTC 1st 2000 datapoints\n",
    "payload = {\"api_key\": apiKey, \"fsym\": \"BTC\", \"tsym\": \"USD\", \"limit\": 2000}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin1 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin1[\"time\"] = pd.to_datetime(BitCoin1[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin1.set_index(\"time\", inplace=True)\n",
    "\n",
    "# 2nd 2000 datapoints\n",
    "payload = {\n",
    "    \"api_key\": apiKey,\n",
    "    \"fsym\": \"BTC\",\n",
    "    \"tsym\": \"USD\",\n",
    "    \"limit\": 2000,\n",
    "    \"toTs\": (1601632800),\n",
    "}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin2 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin2[\"time\"] = pd.to_datetime(BitCoin2[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin2.set_index(\"time\", inplace=True)\n",
    "\n",
    "# 3rd 2000 datapoints\n",
    "payload = {\n",
    "    \"api_key\": apiKey,\n",
    "    \"fsym\": \"BTC\",\n",
    "    \"tsym\": \"USD\",\n",
    "    \"limit\": 2000,\n",
    "    \"toTs\": (1593572400),\n",
    "}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin3 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin3[\"time\"] = pd.to_datetime(BitCoin3[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin3.set_index(\"time\", inplace=True)\n",
    "\n",
    "# 4th 2000 datapoints\n",
    "payload = {\n",
    "    \"api_key\": apiKey,\n",
    "    \"fsym\": \"BTC\",\n",
    "    \"tsym\": \"USD\",\n",
    "    \"limit\": 2000,\n",
    "    \"toTs\": (1596571200),\n",
    "}\n",
    "\n",
    "result = requests.get(url, params=payload).json()\n",
    "\n",
    "BitCoin4 = DataFrame(result[\"Data\"])\n",
    "\n",
    "BitCoin4[\"time\"] = pd.to_datetime(BitCoin4[\"time\"], unit=\"s\")\n",
    "\n",
    "BitCoin4.set_index(\"time\", inplace=True)\n",
    "\n",
    "# combining all bitcoin data (8000 data points)\n",
    "combineData1 = BitCoin2.append(BitCoin1)\n",
    "\n",
    "combineData2 = BitCoin3.append(combineData1)\n",
    "\n",
    "BitCoin = BitCoin4.append(combineData2)  # final BitCoin dataset\n",
    "\n",
    "print(BitCoin.tail(2))\n",
    "# saving btc data set\n",
    "BitCoin.to_csv(\"BitCoinRaw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         high       low      open     close      Lag1  \\\n",
      "time                                                                    \n",
      "2021-02-25 04:00:00  50396.53  49614.02  50277.51  49652.82  50277.51   \n",
      "2021-02-25 05:00:00  50461.08  49587.25  49652.82  50432.31  49652.82   \n",
      "2021-02-25 06:00:00  50613.69  50275.48  50432.31  50503.52  50432.31   \n",
      "2021-02-25 07:00:00  50603.54  50158.30  50503.52  50471.50  50503.52   \n",
      "2021-02-25 08:00:00  50559.02  50222.74  50471.50  50402.66  50471.50   \n",
      "\n",
      "                         Lag2      Lag3      Lag4      Lag5      Lag6  ...  \\\n",
      "time                                                                   ...   \n",
      "2021-02-25 04:00:00  50684.94  50505.54  50535.37  49738.17  48863.06  ...   \n",
      "2021-02-25 05:00:00  50277.51  50684.94  50505.54  50535.37  49738.17  ...   \n",
      "2021-02-25 06:00:00  49652.82  50277.51  50684.94  50505.54  50535.37  ...   \n",
      "2021-02-25 07:00:00  50432.31  49652.82  50277.51  50684.94  50505.54  ...   \n",
      "2021-02-25 08:00:00  50503.52  50432.31  49652.82  50277.51  50684.94  ...   \n",
      "\n",
      "                         Lag8       S_10      Corr      d_20          5EMA  \\\n",
      "time                                                                         \n",
      "2021-02-25 04:00:00  49177.72  49718.841  0.079029  37294.88  50040.133528   \n",
      "2021-02-25 05:00:00  48763.77  49863.121  0.385216  37093.78  50170.859019   \n",
      "2021-02-25 06:00:00  48863.06  49995.701  0.533592  37423.85  50281.746012   \n",
      "2021-02-25 07:00:00  49738.17  50166.474  0.546051  37715.41  50344.997342   \n",
      "2021-02-25 08:00:00  50535.37  50320.434  0.317670  37749.92  50364.218228   \n",
      "\n",
      "                            10EMA         20EMA       mean   returns  \\\n",
      "time                                                                   \n",
      "2021-02-25 04:00:00  49939.584288  49829.772830  50005.275 -1.242484   \n",
      "2021-02-25 05:00:00  50029.170781  49887.157322  50024.165  1.569881   \n",
      "2021-02-25 06:00:00  50115.416094  49945.858530  50444.585  0.141199   \n",
      "2021-02-25 07:00:00  50180.158622  49995.919622  50380.920 -0.063402   \n",
      "2021-02-25 08:00:00  50220.613418  50034.656801  50390.880 -0.136394   \n",
      "\n",
      "                           volume  \n",
      "time                               \n",
      "2021-02-25 04:00:00  1.351763e+08  \n",
      "2021-02-25 05:00:00  1.126336e+08  \n",
      "2021-02-25 06:00:00  7.173013e+07  \n",
      "2021-02-25 07:00:00  8.084536e+07  \n",
      "2021-02-25 08:00:00  1.985792e+07  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"BitCoinRaw.csv\")\n",
    "df.set_index(\"time\", inplace=True)\n",
    "\n",
    "df.drop(columns=[\"conversionType\", \"conversionSymbol\"], axis=1, inplace=True)\n",
    "\n",
    "values = DataFrame(df.close.values)\n",
    "lags = 8\n",
    "columns = [values]\n",
    "for i in range(1, (lags + 1)):\n",
    "    columns.append(values.shift(i))\n",
    "\n",
    "dt = concat(columns, axis=1)\n",
    "\n",
    "columns = [\"Lag\"]\n",
    "for i in range(1, (lags + 1)):\n",
    "    columns.append(\"Lag\" + str(i))\n",
    "dt.columns = columns\n",
    "dt.index = df.index\n",
    "\n",
    "finalDataSet = concat([df, dt], axis=1)\n",
    "\n",
    "finalDataSet.dropna(inplace=True)\n",
    "\n",
    "finalDataSet[\"S_10\"] = finalDataSet[\"close\"].rolling(window=10).mean()\n",
    "\n",
    "finalDataSet[\"Corr\"] = (\n",
    "    finalDataSet[\"close\"].rolling(window=10).corr(finalDataSet[\"S_10\"])\n",
    ")\n",
    "\n",
    "finalDataSet[\"d_20\"] = finalDataSet[\"close\"].shift(480)\n",
    "\n",
    "finalDataSet[\"5EMA\"] = (\n",
    "    finalDataSet[\"close\"].ewm(span=5, adjust=True, ignore_na=True).mean()\n",
    ")\n",
    "\n",
    "finalDataSet[\"10EMA\"] = (\n",
    "    finalDataSet[\"close\"].ewm(span=10, adjust=True, ignore_na=True).mean()\n",
    ")\n",
    "\n",
    "finalDataSet[\"20EMA\"] = (\n",
    "    finalDataSet[\"close\"].ewm(span=20, adjust=True, ignore_na=True).mean()\n",
    ")\n",
    "\n",
    "finalDataSet[\"mean\"] = (finalDataSet[\"low\"] + finalDataSet[\"high\"]) / 2\n",
    "\n",
    "finalDataSet[\"returns\"] = (\n",
    "    (finalDataSet[\"close\"] - finalDataSet[\"open\"]) / finalDataSet[\"open\"] * 100.0\n",
    ")\n",
    "\n",
    "finalDataSet[\"volume\"] = finalDataSet[\"volumeto\"] - finalDataSet[\"volumefrom\"]\n",
    "\n",
    "finalDataSet.drop([\"volumefrom\", \"volumeto\"], 1, inplace=True)\n",
    "\n",
    "finalDataSet.dropna(inplace=True)\n",
    "\n",
    "finalDataSet = finalDataSet.drop([\"Lag\"], axis=1)\n",
    "\n",
    "finalDataSet = finalDataSet.astype(float)\n",
    "\n",
    "finalDataSet = finalDataSet.sort_index(ascending=True)\n",
    "# dataframe.head(2)\n",
    "\n",
    "# save data\n",
    "finalDataSet.to_csv(\"finalDataSet.csv\", header=True)\n",
    "\n",
    "print(finalDataSet.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:174: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import concat, DataFrame\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import sklearn.externals\n",
    "import joblib\n",
    "\n",
    "finalDataSet = pd.read_csv(\"finalDataSet.csv\")\n",
    "finalDataSet.set_index(\"time\", inplace=True)\n",
    "# print(df.tail())\n",
    "\n",
    "\n",
    "foreCastColumn = \"close\"  # creating label\n",
    "\n",
    "foreCastOut = int(12)  # prediction for next 12 hrs\n",
    "\n",
    "finalDataSet[\"label\"] = finalDataSet[foreCastColumn].shift(-foreCastOut)\n",
    "\n",
    "X = np.array(finalDataSet.drop([\"label\"], axis=1))\n",
    "\n",
    "# normalize data\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "X_foreCastOut = X[-foreCastOut:]\n",
    "\n",
    "X = X[:-foreCastOut]\n",
    "\n",
    "finalDataSet.dropna(inplace=True)\n",
    "\n",
    "y = np.array(finalDataSet[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test data set\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 684446691.0199666, tolerance: 13929743.731469138\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25024706.176950004, tolerance: 123419.72625487612\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35962452.99740169, tolerance: 208018.32587141843\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38266311.23774324, tolerance: 220096.64458226462\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51386011.724649034, tolerance: 438252.9609825682\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.85 (+/- 0.28)\n",
      "Intercept: 16309.811601739952\n",
      "Slope: 8173.083563755378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68750980.73926553, tolerance: 783644.8973368459\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# regression model\n",
    "Model = ElasticNet(alpha=0.0001, l1_ratio=0.5, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# cross validated accucary on train set\n",
    "scores = cross_val_score(Model, X_train, y_train, cv=tscv)\n",
    "\n",
    "print(\"Training Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Intercept:\", Model.intercept_)\n",
    "print(\"Slope:\", Model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Training metrics  Validation metrics\n",
      "R-squared                           0.990               0.942\n",
      "Mean Absolute Error               161.021            1370.179\n",
      "Root Mean Squared Error           463.578            1797.669\n",
      "Relative Absolute Error             0.056               0.214\n",
      "Relative Squared Error              0.010               0.058\n"
     ]
    }
   ],
   "source": [
    "# prediction on training\n",
    "trainPredict = Model.predict(X_train)\n",
    "r_squared = r2_score(y_train, trainPredict)\n",
    "mae = np.mean(abs(trainPredict - y_train))\n",
    "rmse = np.sqrt(np.mean((trainPredict - y_train) ** 2))\n",
    "rae = np.mean(abs(trainPredict - y_train)) / np.mean(abs(y_train - np.mean(y_train)))\n",
    "rse = np.mean((trainPredict - y_train) ** 2) / np.mean(\n",
    "    (y_train - np.mean(y_train)) ** 2\n",
    ")\n",
    "sumOfDf = DataFrame(\n",
    "    index=[\n",
    "        \"R-squared\",\n",
    "        \"Mean Absolute Error\",\n",
    "        \"Root Mean Squared Error\",\n",
    "        \"Relative Absolute Error\",\n",
    "        \"Relative Squared Error\",\n",
    "    ]\n",
    ")\n",
    "sumOfDf[\"Training metrics\"] = [r_squared, mae, rmse, rae, rse]\n",
    "\n",
    "# prediction of test\n",
    "testPredict = Model.predict(X_test)\n",
    "r_squared = r2_score(y_test, testPredict)\n",
    "mae = np.mean(abs(testPredict - y_test))\n",
    "rmse = np.sqrt(np.mean((testPredict - y_test) ** 2))\n",
    "rae = np.mean(abs(testPredict - y_test)) / np.mean(abs(y_test - np.mean(y_test)))\n",
    "rse = np.mean((testPredict - y_test) ** 2) / np.mean((y_test - np.mean(y_test)) ** 2)\n",
    "\n",
    "sumOfDf[\"Validation metrics\"] = [r_squared, mae, rmse, rae, rse]\n",
    "sumOfDf = sumOfDf.round(decimals=3)\n",
    "\n",
    "print(sumOfDf)  # accuracy check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file in the current working directory\n",
    "fileName = \"ElasticModel.pkl\"\n",
    "joblib.dump(Model, fileName)\n",
    "\n",
    "# Load from file\n",
    "ElasticModel = joblib.load(fileName)\n",
    "# ElasticModel.predict(X_test)\n",
    "# print(r2_score(y_test, ElasticModel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 hours forecast (hourly):\n",
      "                  time      Forecast\n",
      "0  2021-02-24 21:00:00  49809.559723\n",
      "1  2021-02-24 22:00:00  49683.454960\n",
      "2  2021-02-24 23:00:00  50486.824487\n",
      "3  2021-02-25 00:00:00  51455.979472\n",
      "4  2021-02-25 01:00:00  51587.313733\n",
      "5  2021-02-25 02:00:00  51616.122748\n",
      "6  2021-02-25 03:00:00  51378.035669\n",
      "7  2021-02-25 04:00:00  51043.579239\n",
      "8  2021-02-25 05:00:00  51207.272646\n",
      "9  2021-02-25 06:00:00  51419.231345\n",
      "10 2021-02-25 07:00:00  51383.407690\n",
      "11 2021-02-25 08:00:00  51347.314168\n"
     ]
    }
   ],
   "source": [
    "# forecast future 12 hrs values\n",
    "foreCastFutureValues = DataFrame(ElasticModel.predict(X_foreCastOut))\n",
    "# print(foreCastFutureValues)\n",
    "\n",
    "# assigning names to columns\n",
    "foreCastFutureValues.rename(columns={0: \"Forecast\"}, inplace=True)\n",
    "\n",
    "newDataframe = finalDataSet.tail(foreCastOut)\n",
    "\n",
    "newDataframe.reset_index(inplace=True)\n",
    "\n",
    "# Fixing future datetime\n",
    "newDataframe = newDataframe.append(\n",
    "    DataFrame(\n",
    "        {\n",
    "            \"time\": pd.date_range(\n",
    "                start=newDataframe.time.iloc[-1],\n",
    "                periods=(len(newDataframe) + 1),\n",
    "                freq=\"H\",\n",
    "                closed=\"right\",\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "newDataframe.set_index(\"time\", inplace=True)\n",
    "\n",
    "newDataframe = newDataframe.tail(foreCastOut)\n",
    "\n",
    "foreCastFutureValues.index = newDataframe.index\n",
    "\n",
    "print(\"12 hours forecast (hourly):\")\n",
    "foreCastFutureValues.reset_index(inplace=True)\n",
    "\n",
    "print(foreCastFutureValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaa484b042fbed4d21ad19847f11dc808b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
